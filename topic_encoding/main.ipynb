{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2232e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this at the top of your notebook\n",
    "import torch.multiprocessing as mp\n",
    "# Set multiprocessing method to 'spawn' instead of 'fork'\n",
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64029041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "sentence_encoder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")  # dim=384\n",
    "fields = ['title', 'description', 'channel', 'date']  # etc.\n",
    "field_embeds = sentence_encoder.encode(fields, convert_to_tensor=True)  # shape: [num_fields, 384]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f61f112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "class MetadataFusion(nn.Module):\n",
    "    def __init__(self, hidden_dim=384, num_fields=4):\n",
    "        super().__init__()\n",
    "        config = BertConfig(\n",
    "            hidden_size=hidden_dim,\n",
    "            num_attention_heads=6,\n",
    "            num_hidden_layers=2,\n",
    "            intermediate_size=hidden_dim * 4,\n",
    "            max_position_embeddings=num_fields + 1,  # +1 for [CLS]\n",
    "            num_labels=1\n",
    "        )\n",
    "        self.bert = BertModel(config)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, hidden_dim))  # [CLS] token\n",
    "        \n",
    "        # Positional embeddings to help identify which field is which\n",
    "        self.field_type_embed = nn.Embedding(num_fields, hidden_dim)\n",
    "        self.num_fields = num_fields\n",
    "\n",
    "    def forward(self, field_embeddings):\n",
    "        \"\"\"\n",
    "        field_embeddings: Tensor of shape [batch_size, num_fields, hidden_dim]\n",
    "        \"\"\"\n",
    "        batch_size = field_embeddings.size(0)\n",
    "        device = field_embeddings.device\n",
    "        \n",
    "        # Add learned field-type embeddings (field identity)\n",
    "        field_positions = torch.arange(self.num_fields, device=device)\n",
    "        field_type_bias = self.field_type_embed(field_positions)  # [num_fields, hidden_dim]\n",
    "        field_type_bias = field_type_bias.unsqueeze(0).expand(batch_size, -1, -1)  # [batch, num_fields, hidden_dim]\n",
    "        enriched_fields = field_embeddings + field_type_bias\n",
    "        \n",
    "        # Prepend [CLS] token\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # shape: [batch_size, 1, hidden_dim]\n",
    "        tokens = torch.cat([cls_tokens, enriched_fields], dim=1)  # [batch, num_fields + 1, dim]\n",
    "\n",
    "        attention_mask = torch.ones(tokens.shape[:2], dtype=torch.long).to(tokens.device)\n",
    "        output = self.bert(inputs_embeds=tokens, attention_mask=attention_mask)\n",
    "        fused = output.last_hidden_state[:, 0]  # take [CLS] token\n",
    "        return fused  # shape: [batch_size, hidden_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a23f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "NUMBER_WORKERS = 10\n",
    "PRE_FETCH = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9808f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../dataset/train_with_flashiness.csv')\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbb91bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MetadataDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        title = row['title']\n",
    "        description = row['description']\n",
    "        channel = row['channel']\n",
    "        date = row['date']\n",
    "        target = row['views']\n",
    "        \n",
    "        # Encode fields\n",
    "        field_embeddings = sentence_encoder.encode([title, description, channel, date], convert_to_tensor=True)\n",
    "        \n",
    "        return field_embeddings, torch.tensor(target, dtype=torch.float32)\n",
    "    \n",
    "train_dataset = MetadataDataset(df_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUMBER_WORKERS, prefetch_factor=PRE_FETCH)\n",
    "val_dataset = MetadataDataset(df_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUMBER_WORKERS, prefetch_factor=PRE_FETCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab5f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add regressor to the model\n",
    "class MetadataRegressor(nn.Module):\n",
    "    def __init__(self, hidden_dim=384, num_fields=4):\n",
    "        super().__init__()\n",
    "        self.fusion = MetadataFusion(hidden_dim, num_fields)\n",
    "        self.regressor = nn.Linear(hidden_dim, 1)  # Assuming regression task\n",
    "\n",
    "    def forward(self, field_embeddings):\n",
    "        fused = self.fusion(field_embeddings)\n",
    "        output = self.regressor(fused)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6653197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import gc  # Add garbage collector\n",
    "\n",
    "# First, clear any existing cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model = MetadataRegressor().to(device)\n",
    "\n",
    "# Move field embeddings to device\n",
    "field_embeds = field_embeds.to(device)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.HuberLoss(delta=1.0) # Huber loss is less sensitive to outliers than MSE\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "batch_losses = []\n",
    "\n",
    "# Create a function to update the plot\n",
    "def plot_losses():\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot batch losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(batch_losses)\n",
    "    plt.title('Loss per Batch')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot epoch losses\n",
    "    plt.subplot(1, 3, 2)\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Training')\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Validation')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd8ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib64/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/lib64/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'MetadataDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    for i, (imgs, targets) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(imgs)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        batch_losses.append(batch_loss)\n",
    "        total_train_loss += loss.item() * len(imgs)\n",
    "        \n",
    "        # Move tensors to CPU to free GPU memory\n",
    "        imgs = imgs.cpu()\n",
    "        targets = targets.cpu()\n",
    "        \n",
    "        # Optionally plot every N batches\n",
    "        if (i + 1) % 10 == 0:  # Adjust frequency as needed\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS} | Batch {i+1}/{len(train_loader)} | Loss: {batch_loss:.4f}\")\n",
    "            \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            val_loss = loss_fn(outputs, targets)\n",
    "            total_val_loss += val_loss.item() * len(imgs)\n",
    "            \n",
    "            # Move tensors to CPU to free GPU memory\n",
    "            imgs = imgs.cpu()\n",
    "            targets = targets.cpu()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / len(train_dataset)\n",
    "    avg_val_loss = total_val_loss / len(val_dataset)\n",
    "    \n",
    "    # Store losses for plotting\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # Free up memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    plot_losses()\n",
    "    \n",
    "plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.fusion.state_dict(), 'metadata_fusion.pth')\n",
    "torch.save(model.regressor.state_dict(), 'metadata_regressor.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af40f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load test data\n",
    "print(f\"Test dataset loaded with {len(df_val)} samples\")\n",
    "\n",
    "# Recreate model architecture\n",
    "model = MetadataRegressor()\n",
    "model.fusion.load_state_dict(torch.load('metadata_fusion.pth'))\n",
    "model.regressor.load_state_dict(torch.load('metadata_regressor.pth'))\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "actual = []\n",
    "ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, targets in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        \n",
    "        # Store predictions and ground truth\n",
    "        predictions.extend(outputs.cpu().numpy().tolist())\n",
    "        actual.extend(targets.numpy().tolist())\n",
    "\n",
    "ids = df_val['id'].values.tolist()\n",
    "# Create results dataframe\n",
    "results = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'predicted_views': predictions\n",
    "})\n",
    "\n",
    "# If we have actual flashiness values in the test set, calculate metrics\n",
    "if \"views\" in df_val.columns:\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    \n",
    "    mse = mean_squared_error(actual, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual, predictions)\n",
    "    r2 = r2_score(actual, predictions)\n",
    "    \n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    \n",
    "    # Plot predictions vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(actual, predictions, alpha=0.5)\n",
    "    plt.plot([min(actual), max(actual)], [min(actual), max(actual)], 'r--')\n",
    "    plt.xlabel('Actual Views')\n",
    "    plt.ylabel('Predicted Views')\n",
    "    plt.title('Predicted vs Actual Views')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# View the flashiest images according to the model\n",
    "results_sorted = results.sort_values(by='predicted_views', ascending=False)\n",
    "\n",
    "# Display top 5 most attractive videos according to the model\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.suptitle(\"Top 5 Most Attractive Videos (According to Model)\", fontsize=16)\n",
    "\n",
    "for i in range(5):\n",
    "    if i < len(results_sorted):\n",
    "        row = results_sorted.iloc[i]\n",
    "        img_path = f\"../dataset/train_val/{row['id']}.jpg\"\n",
    "        \n",
    "        if os.path.exists(img_path):\n",
    "            img_path = img_path\n",
    "        else:\n",
    "            print(f\"Image not found: {row['id']}\")\n",
    "            continue\n",
    "            \n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Views: {row['predicted_views']:.2f}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
